{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paolo1acosta1/ee104_lab8_neural_networls/blob/main/Lab8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USbjRj6_5vUd"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install h5py\n",
        "!pip install Matplotlib\n",
        "!pip install numpy\n",
        "!pip install np_utils\n",
        "!pip install scipy==1.1.0\n",
        "!pip install Pillow\n",
        "!pip install Scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1cVRI-WrdRQ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ],
      "metadata": {
        "id": "Zt9Nw9iLEJTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJg8KRmc273w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d520c765-896a-4c0f-b356-0c49598890b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDjHIkG23CBr"
      },
      "outputs": [],
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2))\n",
        "std = np.std(x_train,axis=(0,1,2))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XRGsLVs3JNp"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzhwiONO3M3r"
      },
      "outputs": [],
      "source": [
        "reg2=None\n",
        "num_filters2=32\n",
        "ac2='relu'\n",
        "adm2=optimizers.Adam(lr=0.001,decay=0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "opt2=adm2\n",
        "drop_dense2=0.5\n",
        "drop_conv2=0.2\n",
        "img_rows, img_cols , channels= 32,32,3\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(num_filters2, (3, 3), activation=ac2, kernel_regularizer=reg2, input_shape=(img_rows, img_cols, channels),padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 16x16x3xnum_filters\n",
        "model.add(Dropout(drop_conv2))\n",
        "\n",
        "model.add(Conv2D(2*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(2*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 8x8x3x(2*num_filters)\n",
        "model.add(Dropout(drop_conv2))\n",
        "\n",
        "model.add(Conv2D(4*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(4*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 4x4x3x(4*num_filters)\n",
        "model.add(Dropout(drop_conv2))\n",
        "\n",
        "model.add(Conv2D(8*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(8*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 4x4x3x(4*num_filters)\n",
        "model.add(Dropout(drop_conv2))\n",
        "\n",
        "model.add(Conv2D(16*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(16*num_filters2, (3, 3), activation=ac2,kernel_regularizer=reg2,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 4x4x3x(4*num_filters)\n",
        "model.add(Dropout(drop_conv2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=ac2,kernel_regularizer=reg2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop_dense2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt2)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSrk3l-CAQVd"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC0glFcw3vog"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
        "                        epochs=90,\n",
        "                    steps_per_epoch = len(x_train)/128,\n",
        "                        callbacks=[LearningRateScheduler(lr_schedule)],\n",
        "                        validation_data=(x_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, \n",
        "                    validation_data=(x_train, y_train))"
      ],
      "metadata": {
        "id": "Nr2TJHON0xNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kWskEd53wwJ"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_train,  y_train, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url = \"https://ichef.bbci.co.uk/news/976/cpsprodpb/67CF/production/_108857562_mediaitem108857561.jpg \"\n",
        "#sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "sunflower_path = tf.keras.utils.get_file(origin=sunflower_url)  # took away the 'Red_sunflower', \n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "1icb8ni2z2-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab8.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPRT3bReO/pmCKxlx1xxXIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}